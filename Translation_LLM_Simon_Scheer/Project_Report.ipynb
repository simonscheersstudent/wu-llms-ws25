{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3525f2-f51b-4095-8b04-594e358b3803",
   "metadata": {},
   "source": [
    "# Translation Model with a focus on the languages english, german and spanish\n",
    "    by Simon Scheer\n",
    "## Project Description\n",
    "The project aims to create a fine tuned version of the `facebook/mbart-large-50-many-to-many-mmt` model accessed through hugging face. The goal of this project was to create a fine tuning pipeling, by preparing a datset to be used for fine tuning the model, fine tuning the model, evaluating the model by creating a sample of 500 test translations and then afterwards using the fine tuned model to translate written as well as spoken language in spanish, english and german. The model chosen has 600 million parameters and for time reasons fine tuning all of the parameters would have not worked out therefore the chosen method was freezing most parameters and fine tuning only around 4 Million with the chosen trainings dataset this led still to a fine tuning duration of over 14 hours just for one epoch. After fine tuning the model functions were created to transcribe audio and detect the language spoken or written in the input source then the fine tuned model is used for translating the input and afterwards the output can be seen as written text but can be also listened to as an audio output. \n",
    "\n",
    "## Project Content\n",
    " 1. **Import of python libraries used for the model**\n",
    "\n",
    " 2. **Fine tuning pipeline**\n",
    "   \n",
    "       **2.1. Data preparation**\n",
    "   \n",
    "       **2.2. Model Setup**\n",
    "   \n",
    "       **2.3. Tokenization**\n",
    "\n",
    "       **2.4. Training Setup**\n",
    "\n",
    "       **2.5. Training**\n",
    "\n",
    "       **2.6. Load Models**\n",
    "\n",
    "       **2.7. Evaluation**\n",
    "\n",
    "3. **Implementation and Use of Translation Functions**\n",
    "\n",
    "\n",
    "## 1. Import of python libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4853c384-890d-4601-aaa8-e17e27e4b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import sentencepiece\n",
    "import transformers\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import ClassLabel, load_dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "import copy\n",
    "import whisper\n",
    "import sounddevice\n",
    "from scipy.io.wavfile import write\n",
    "from langdetect import detect\n",
    "from TTS.api import TTS\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce1b819-72e6-4338-941a-1efd037995ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f6ebf-7ef9-4896-bdfc-163e5773e202",
   "metadata": {},
   "source": [
    "## 2. Fine tuning pipeline\n",
    "\n",
    "### 2.1. Data Preparation\n",
    "\n",
    "For the datasets I decided to use the `opus_books` dataset from [hugging face](https://huggingface.co/datasets/Helsinki-NLP/opus_books) since it provides human translated translations for all language pairs the model was fine tuned on from `german to english`, `germand to spanish` and `english to spanish`. The dataset provides tens of thousands translated chunks to work with. The only downside is some books are written in rather old forms of the language and do not use words that are used in every day life sometimes. Since the dataset provides translation always only in one direction I decided to use also the reversed datasets for `english to german`, `spanish to german` and `spanish to english` so the performance should be well in both directions but it has to be taken into account that the transaltions are not direct word for word transaltion but human translations which might lead to some unexpected results in some cases since the transaltion does not seem correct since the translator chose a suiting translation for that case but not in general.\n",
    "\n",
    "#### 2.1.1. Loading Dataset from Hugging Face Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393e1017-7357-4bb1-a9d6-b940a47d581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_en_data = datasets.load_dataset(\"opus_books\", \"de-en\")\n",
    "en_es_data = datasets.load_dataset(\"opus_books\", \"en-es\")\n",
    "de_es_data = datasets.load_dataset(\"opus_books\", \"de-es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50810b63-b19d-4a27-9175-fb58cb5a30b6",
   "metadata": {},
   "source": [
    "#### 2.1.2 Converting Structure\n",
    "Since the structure of the model input and the `opus_books` dataset differ a bit the data needs to be convertedinto the correct format. The following function is also used to preprocess the data a little bit excluding links and too long chunks for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5126c8-8547-4995-837b-5e231938b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_train(ds, src_key, tgt_key, src_lang, tgt_lang):\n",
    "    \"\"\"Convert dataset to training format with filtering\"\"\"\n",
    "    converted_data = []\n",
    "    \n",
    "    for i, row in enumerate(ds[\"train\"]):\n",
    "        if i == 0:  \n",
    "            continue\n",
    "        \n",
    "        source_text = row[\"translation\"].get(src_key, \"\").strip()\n",
    "        target_text = row[\"translation\"].get(tgt_key, \"\").strip()\n",
    "\n",
    "        if len(source_text) < 2 or len(target_text) < 2:\n",
    "            continue\n",
    "        if len(source_text.split()) > 80 or len(target_text.split()) > 80:\n",
    "            continue\n",
    "        if \"http\" in source_text or \"http\" in target_text:\n",
    "            continue\n",
    "\n",
    "        converted_data.append({\n",
    "            \"source\": source_text,\n",
    "            \"target\": target_text,\n",
    "            \"src_lang\": src_lang,\n",
    "            \"tgt_lang\": tgt_lang\n",
    "        })\n",
    "    \n",
    "    return converted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cc075-5884-4b24-a459-1b18f9c0154f",
   "metadata": {},
   "source": [
    "The created function is also used for creating the reversed dataset mentioned before. And then the datasets are all added together to get a `full_data` dataset which can be further processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa4f2ab-74a8-4773-b94f-187f90e0719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_to_en = convert_to_train(de_en_data, \"de\", \"en\", \"de_DE\", \"en_XX\")\n",
    "en_to_de = convert_to_train(de_en_data, \"en\", \"de\", \"en_XX\", \"de_DE\")\n",
    "en_to_es = convert_to_train(en_es_data, \"en\", \"es\", \"en_XX\", \"es_XX\")\n",
    "es_to_en = convert_to_train(en_es_data, \"es\", \"en\", \"es_XX\", \"en_XX\")\n",
    "de_to_es = convert_to_train(de_es_data, \"de\", \"es\", \"de_DE\", \"es_XX\")\n",
    "es_to_de = convert_to_train(de_es_data, \"es\", \"de\", \"es_XX\", \"de_DE\")\n",
    "full_data = (de_to_en + en_to_de + en_to_es + es_to_en + de_to_es + es_to_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae86c83-6334-4e97-8d13-d601dabb6ef9",
   "metadata": {},
   "source": [
    "After the `full_data` dataset is created it has to be converted to a hugging face dataset to be used as input in the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60295cd6-1e73-4ec5-935c-9d751affab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_list(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe04f49-1487-4c41-b036-8b256f44dfb8",
   "metadata": {},
   "source": [
    "Since I tied first to use the whole dataset in no certain order and it produced not very good outputs I decided to group the data by task and with task is meant the direction of translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac51af43-7afd-4184-afc9-7d3226b7d614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca99f07d72a347ae8c3506bd09347ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/337018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96622b83a3c949649affec066680e094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/337018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_task_to_data(data):\n",
    "    data[\"task\"] = data[\"src_lang\"] + \" -> \" + data[\"tgt_lang\"]\n",
    "    return data\n",
    "\n",
    "dataset_with_tasks = dataset.map(add_task_to_data)\n",
    "\n",
    "task_names = sorted(set(dataset_with_tasks[\"task\"]))\n",
    "\n",
    "dataset_with_tasks = dataset_with_tasks.cast_column(\n",
    "    \"task\",\n",
    "    ClassLabel(names=task_names)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f927202-8143-46ed-b257-692b00cbb154",
   "metadata": {},
   "source": [
    "#### 2.1.3 Creating Test and Training Dataset\n",
    "After creating the dataset with the taks column the dataset will be split into a train and test datasplit where the `test_size` was chosen to be very small since as much as possible data shpuld have been used for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23c7ba29-9dde-4a14-885e-37141abaf37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset_with_tasks.train_test_split(\n",
    "    test_size=0.05,\n",
    "    stratify_by_column=\"task\",\n",
    "    seed=42\n",
    ")\n",
    "train_data = splits[\"train\"]\n",
    "test_data = splits[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5ff8b-e5e1-4e89-b7e1-fde9a9ced38c",
   "metadata": {},
   "source": [
    "### 2.2. Model Setup\n",
    "\n",
    "As mentioned in the project description because of missing grpahical processing unit in my own latop the performance of training showed an expected training time of many days since this seemed to be unattainable in the project scope so I decided to use `LoRA` for freezing many parameters so my model can concentrate on some parameters (still around 4 Million) to be fine tuned.\n",
    "\n",
    "#### 2.2.1. Loading the Model from Hugging Face \n",
    "More information on the model can be found on [Hugging Face](https://huggingface.co/facebook/mbart-large-50-many-to-many-mmt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c124a67b-2b38-4ef3-a958-8a0159b0a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9cd95-42e8-478e-94a4-e875516d9c3e",
   "metadata": {},
   "source": [
    "#### 2.2.2. Using LoRA to optimize Fine tuning\n",
    "Since the training time for the chosen model `facebook/mbart-large-50-many-to-many-mmt` was out of scope another model would have been needed but by then the preprcosessing steps were already done and the model seemed to be very suitable for the use case so I decided to do some research of how to optimize the fine tuning and I found the option of using `LoRA` which essentially allows to fine tune only a certain amount of the model which should still lead to improvements in model performance. `LoRA` works by adding lightweight pieces to the original model instead opf training the whole model again it fine tunes just a set of parameters. A really important parameter which needs to be set to false is the `inference_mode` parameter if it is set to true the model actually does not train and save the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba449812-719e-4c92-a2e9-452f134da4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 615,598,080 || trainable%: 0.7665\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    inference_mode=False  \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69923a8c-1abc-40e0-b534-ce552fce7901",
   "metadata": {},
   "source": [
    "### 2.3. Tokenization\n",
    "This part tokenizes the data and sorts it by task again so we keep the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51e10c18-bfff-48ad-b64e-5141a4779069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sort(\"task\")\n",
    "test_data = test_data.sort(\"task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d2fc29-7cf6-4b68-8c1b-914557a3cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    tokenizer.src_lang = data[\"src_lang\"]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        data[\"source\"], \n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    tokenizer.tgt_lang = data[\"tgt_lang\"]\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        text_target=data[\"target\"], \n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    labels_ids = labels[\"input_ids\"]\n",
    "    labels_ids = [\n",
    "        (token if token != tokenizer.pad_token_id else -100) \n",
    "        for token in labels_ids\n",
    "    ]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels_ids\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c624e7-04a2-4f0d-b7a9-95de72fc7c93",
   "metadata": {},
   "source": [
    "Implementation of the tokenization function created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9cd6878-d32d-4545-867e-87cba143d7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c857aa52093842b8b6e3241607fa7b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7496bcad56bc4fa6978e85c3bae5e723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_tokenized = train_data.map(tokenization, batched=False)\n",
    "test_data_tokenized = test_data.map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a45f-e806-4624-8db1-e556fd0d9b86",
   "metadata": {},
   "source": [
    "Remove the unnecessary columns (the columns containing the not tokenized data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2233a8cb-f7a2-45c6-a297-2b4029e3f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokenized = train_data_tokenized.remove_columns(train_data.column_names)\n",
    "test_data_tokenized = test_data_tokenized.remove_columns(test_data.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7895ce-e80f-4eba-be3e-916b5dc39675",
   "metadata": {},
   "source": [
    "### 2.4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b822e3fb-14b7-4bfd-9ba7-b4e50d15de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./mbart_lora_fixed\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data_tokenized,\n",
    "    eval_dataset=test_data_tokenized,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42bc615-98d7-486d-962c-d8801f229413",
   "metadata": {},
   "source": [
    "### 2.5. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cd2f7-5763-42c8-b467-dcf5588dd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecab20c-1988-487b-aada-b5717017561f",
   "metadata": {},
   "source": [
    "Saving the models created by the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39927613-265d-4a5a-84ba-dc71276f83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"mbart50_lora_final_fixed\")\n",
    "tokenizer.save_pretrained(\"mbart50_lora_final_fixed\")\n",
    "model.save_pretrained(\"mbart50_lora_final_fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587fd97e-30e1-4c78-8c2b-afb882e6e8ae",
   "metadata": {},
   "source": [
    "### 2.6. Load Models \n",
    "Now the fine tuned model as well as the base model are loaded again so they can be afterwards evaluated, since not the whole model was fine tuned but only some parameters the base model and the adapter have to be combined which leads to the inference model being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4a56b98-719f-4c4d-ae8a-8108fb716398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MBartForConditionalGeneration(\n",
       "      (model): MBartModel(\n",
       "        (shared): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "        (encoder): MBartEncoder(\n",
       "          (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "          (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x MBartEncoderLayer(\n",
       "              (self_attn): MBartAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): ReLU()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): MBartDecoder(\n",
       "          (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n",
       "          (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x MBartDecoderLayer(\n",
       "              (self_attn): MBartAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): MBartAttention(\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_comparison = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "base_model_comparison = base_model_comparison.to(device)\n",
    "base_model_comparison.eval()\n",
    "\n",
    "base_model_finetuned = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer_inference = MBart50TokenizerFast.from_pretrained(\"mbart50_lora_final_fixed\")\n",
    "model_inference = PeftModel.from_pretrained(base_model_finetuned, \"mbart50_lora_final_fixed\")\n",
    "model_inference = model_inference.to(device)\n",
    "model_inference.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca68931-139a-4722-b675-e9498983d52e",
   "metadata": {},
   "source": [
    "Creation of translation function for comaprison of both models used for creation of dataset used to compare each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "38c39ff7-8dd5-431a-b7d4-1652cab2535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, src=\"en_XX\", tgt=\"es_XX\"):\n",
    "    tokenizer_inference.src_lang = src\n",
    "    \n",
    "    encoded = tokenizer_inference(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    #model_inputs = {k: v.to(model_inference.device) for k, v in encoded.items()}\n",
    "    model_inputs = encoded.to(model_inference.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model_inference.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer_inference.lang_code_to_id[tgt],\n",
    "            max_length=128,\n",
    "            num_beams=5\n",
    "        )\n",
    "    \n",
    "    return tokenizer_inference.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "def translate_base(text, src=\"en_XX\", tgt=\"es_XX\"):\n",
    "    tokenizer.src_lang = src\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    #model_inputs = {k: v.to(base_model_comparison.device) for k, v in encoded.items()}\n",
    "    model_inputs = encoded.to(model_inference.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_tokens = base_model_comparison.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[tgt],\n",
    "            max_length=128,\n",
    "            num_beams=5\n",
    "        )\n",
    "    \n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e7447-ac39-423c-9b7e-85f0fba7b57e",
   "metadata": {},
   "source": [
    "### 2.7. Evaluation of fine tuned model cpmpared to base level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c11914e3-5580-4c23-a171-d95b0b6e298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations(data, num_samples=500, save_path=\"evaluation_results.csv\"):\n",
    "    results = []\n",
    "    \n",
    "    sample_data = data.select(range(min(num_samples, len(data))))\n",
    "    \n",
    "    for example in tqdm(sample_data):\n",
    "        base_translation = translate_base(\n",
    "            example[\"source\"], \n",
    "            src=example[\"src_lang\"], \n",
    "            tgt=example[\"tgt_lang\"]\n",
    "        )\n",
    "        \n",
    "        fine_tuned_translation = translate(\n",
    "            example[\"source\"], \n",
    "            src=example[\"src_lang\"], \n",
    "            tgt=example[\"tgt_lang\"]\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"input\": example[\"source\"],\n",
    "            \"reference\": example[\"target\"],\n",
    "            \"base_translation\": base_translation,\n",
    "            \"fine_tuned_translation\": fine_tuned_translation,\n",
    "            \"task\": f\"{example['src_lang']}->{example['tgt_lang']}\"\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "befd8935-353c-4b8a-82b3-cb7f7c28cb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [16:23<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_df = evaluate_translations(test_data, num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "200cab16-906a-4601-a6da-3f4ce7bc169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.76701576329957 22.371763468091533 3.6047477047919614\n"
     ]
    }
   ],
   "source": [
    "bleu_base = sacrebleu.corpus_bleu(\n",
    "    eval_df[\"base_translation\"].tolist(), \n",
    "    [eval_df[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "bleu_fine_tuned = sacrebleu.corpus_bleu(\n",
    "    eval_df[\"fine_tuned_translation\"].tolist(), \n",
    "    [eval_df[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "print(bleu_base.score, bleu_fine_tuned.score, bleu_fine_tuned.score - bleu_base.score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb446726-9549-4562-b0a8-203e15fb1e04",
   "metadata": {},
   "source": [
    "## 3. Second Iteration of fine tuning\n",
    "After the first iteration of the fine tuning was concluded and I still wanted better results I decided to fine tune the model on a second different dataset to try to improve the model even more. For this reason there will now be a second version of most steps described before already some may be even redundand because they were already used before some new functions. For this time we used the `Amani27/massive_transaltion_dataset` and created a trainingdataset of around 65.000 translation samples. This dataset contains more modern every day translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf413b6-16db-4fc7-b272-83c097474380",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = datasets.load_dataset(\"Amani27/massive_translation_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d21cc9-7bf9-4e8a-aee7-6e4e9ff4503b",
   "metadata": {},
   "source": [
    "### 3.1. Dataset Preparation\n",
    "Since the first dataset we used and the second dataset have two different structures we needed a new function to convert the dataset so we can use it as input for the tokenizer later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33402816-fa4d-4d24-84ac-b23bcc8a318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_amani_datasets( src_lang, tgt_lang, dataset=dataset_2):\n",
    "\n",
    "    output_data={}\n",
    "    \n",
    "    match src_lang:\n",
    "        case \"en_US\":\n",
    "            lang_in = \"en_XX\"\n",
    "        case \"de_DE\":\n",
    "            lang_in = src_lang\n",
    "        case \"es_ES\":\n",
    "            lang_in = \"es_XX\"\n",
    "            \n",
    "    match tgt_lang:\n",
    "        case \"en_US\":\n",
    "            lang_out = \"en_XX\"\n",
    "        case \"de_DE\":\n",
    "            lang_out = tgt_lang\n",
    "        case \"es_ES\":\n",
    "            lang_out = \"es_XX\"\n",
    "        \n",
    "    source_text = dataset[\"train\"][src_lang]\n",
    "    target_text = dataset[\"train\"][tgt_lang]\n",
    "\n",
    "    output_data = datasets.Dataset.from_dict({\n",
    "        \"source\": list(dataset[\"train\"][src_lang]),\n",
    "        \"target\": list(dataset[\"train\"][tgt_lang]),\n",
    "        \"src_lang\": [lang_in] * len(dataset[\"train\"]),\n",
    "        \"tgt_lang\": [lang_out] * len(dataset[\"train\"]),\n",
    "    })\n",
    "    return output_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef935e3-fd38-43e0-be35-0f2728edb2e5",
   "metadata": {},
   "source": [
    "This function is a bit more efficient thancthe one created earlier since it already outputs a hugging face dataset structure for each function call and the datasets have to be just combined in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a74d7e7-a672-4f2f-b334-49a850861211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_en_to_de = create_amani_datasets( src_lang=\"en_US\", tgt_lang=\"de_DE\")\n",
    "dataset2_de_to_en = create_amani_datasets( src_lang=\"de_DE\", tgt_lang=\"en_US\")\n",
    "dataset2_en_to_es = create_amani_datasets( src_lang=\"en_US\", tgt_lang=\"es_ES\")\n",
    "dataset2_de_to_es = create_amani_datasets( src_lang=\"de_DE\", tgt_lang=\"es_ES\")\n",
    "dataset2_es_to_de = create_amani_datasets( src_lang=\"es_ES\", tgt_lang=\"de_DE\")\n",
    "dataset2_es_to_en = create_amani_datasets( src_lang=\"es_ES\", tgt_lang=\"en_US\")\n",
    "dataset2 = datasets.concatenate_datasets([dataset2_en_to_de,dataset2_de_to_en,dataset2_en_to_es,dataset2_de_to_es,dataset2_es_to_de,dataset2_es_to_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a27030-09ca-403e-b960-53da4cb1fc95",
   "metadata": {},
   "source": [
    "As mentioned above in the first iteration this code is used to create a column containing the translation direction to later group by this column to have the correct order even after splitting in training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7740e2f8-96dd-4f8c-95bf-a5547a237a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d178ed1d511249faabc93c131afaab00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64abad28c6243b9bdf6476ebf320a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/69084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_with_tasks2 = dataset2.map(add_task_to_data)\n",
    "\n",
    "dataset_with_tasks2 = dataset_with_tasks2.cast_column(\n",
    "    \"task\",\n",
    "    ClassLabel(names=task_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48367a23-90db-43a3-950c-d77ea40aacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits2 = dataset_with_tasks2.train_test_split(\n",
    "    test_size=0.05,\n",
    "    stratify_by_column=\"task\",\n",
    "    seed=42\n",
    ")\n",
    "train_data2 = splits2[\"train\"]\n",
    "test_data2 = splits2[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043575a-11c2-4926-ab51-c06540a8d6bc",
   "metadata": {},
   "source": [
    "### 3.2. Load first iteration of fine tuned model\n",
    "After creating the dataset we need to get the tokenizer once again and also load the models and merge the base_model with the fine tuned adapter to work on the merged model for the second iteration of fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ac6b162-8d08-4977-9cac-669d26b731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "base_model_finetuned2 = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "model_inference2 = PeftModel.from_pretrained(base_model_finetuned2, \"mbart50_lora_final_fixed\")\n",
    "merged_model2 = model_inference2.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4789565-50f5-4d9b-9897-e5982d7269f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 615,598,080 || trainable%: 0.7665\n"
     ]
    }
   ],
   "source": [
    "lora_config2 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    inference_mode=False  \n",
    ")\n",
    "\n",
    "model2 = get_peft_model(merged_model2, lora_config2)\n",
    "model2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc7346-6b79-4582-9ae6-c250016189c1",
   "metadata": {},
   "source": [
    "### 3.3. Tokenization Second Iteration\n",
    "After the model and the tokenizer are loaded the steps of tokenozation which use the same function as a bove can be done. First the dataset is sorted by task then the `tokenization`is used to tokenize all the data and afterwards the string input columns are removed so that only the numerical columns are kept in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f9fd08d-55c8-4f4d-9bbc-eb52acba5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = train_data2.sort(\"task\")\n",
    "test_data2 = test_data2.sort(\"task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed9a500-51de-40a1-a895-3c26de3060a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332f6e56808342fba217ce4d7bb56bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c12f89e3c84804bc603a27fa9557a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3455 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_tokenized2 = train_data2.map(tokenization, batched=False)\n",
    "test_data_tokenized2 = test_data2.map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f114aab2-746b-40e5-95e0-2c63b35584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokenized2 = train_data_tokenized2.remove_columns(train_data2.column_names)\n",
    "test_data_tokenized2 = test_data_tokenized2.remove_columns(test_data2.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b45f4-552c-458e-a3c7-6e4aa642395d",
   "metadata": {},
   "source": [
    "### 3.4. Training Setup for the second Iteration\n",
    "we used more or less the same training setup but since we have a smaller dataset for the second iteration (1/5 of dataset one) it was decided that a higher number of the parameter `num_train_epochs`will be used (3 instead of 1 in the first iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "842960e5-ea15-4c0c-805d-23a86bd9a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator2 = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model2,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "training_args2 = transformers.TrainingArguments(\n",
    "    output_dir=\"./mbart_lora_fixed_round2\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"loss\",\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer2 = transformers.Trainer(\n",
    "    model=model2,\n",
    "    args=training_args2,\n",
    "    train_dataset=train_data_tokenized2,\n",
    "    eval_dataset=test_data_tokenized2,\n",
    "    data_collator=data_collator2,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bca930-1c98-44a7-b96f-0f5297bfc6d7",
   "metadata": {},
   "source": [
    "### 3.4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d226203-5f8a-4dae-bbdd-c181e11dc420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49224' max='49224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49224/49224 9:34:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.515100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.330600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.402300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.311100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.268200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.239200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>1.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>1.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>1.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>1.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>1.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>1.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>1.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>1.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>1.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>1.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>1.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.173800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>1.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>1.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>1.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>1.187800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>1.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>1.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>1.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>1.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>1.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>1.212700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>1.205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>1.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>1.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>1.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>1.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>1.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>1.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>1.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>1.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>1.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.074300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>1.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>1.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>1.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>1.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>1.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>1.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>1.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>1.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>1.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20600</td>\n",
       "      <td>1.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20800</td>\n",
       "      <td>1.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.067300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21200</td>\n",
       "      <td>1.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>1.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>1.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21800</td>\n",
       "      <td>1.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22200</td>\n",
       "      <td>1.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22400</td>\n",
       "      <td>1.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22600</td>\n",
       "      <td>1.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>1.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23200</td>\n",
       "      <td>1.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23400</td>\n",
       "      <td>1.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23600</td>\n",
       "      <td>1.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23800</td>\n",
       "      <td>1.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24200</td>\n",
       "      <td>0.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24400</td>\n",
       "      <td>1.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24600</td>\n",
       "      <td>1.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24800</td>\n",
       "      <td>1.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>1.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25400</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25600</td>\n",
       "      <td>1.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25800</td>\n",
       "      <td>1.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26200</td>\n",
       "      <td>1.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>1.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26600</td>\n",
       "      <td>1.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26800</td>\n",
       "      <td>1.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.967800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27200</td>\n",
       "      <td>1.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27400</td>\n",
       "      <td>1.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>0.986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27800</td>\n",
       "      <td>0.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28200</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28400</td>\n",
       "      <td>0.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28600</td>\n",
       "      <td>1.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28800</td>\n",
       "      <td>0.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29200</td>\n",
       "      <td>1.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29400</td>\n",
       "      <td>0.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29600</td>\n",
       "      <td>0.957900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29800</td>\n",
       "      <td>1.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30200</td>\n",
       "      <td>0.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30400</td>\n",
       "      <td>1.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30600</td>\n",
       "      <td>0.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30800</td>\n",
       "      <td>0.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31200</td>\n",
       "      <td>0.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31400</td>\n",
       "      <td>1.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31600</td>\n",
       "      <td>0.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31800</td>\n",
       "      <td>1.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32200</td>\n",
       "      <td>0.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>0.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32600</td>\n",
       "      <td>0.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32800</td>\n",
       "      <td>0.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33200</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33400</td>\n",
       "      <td>0.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33600</td>\n",
       "      <td>0.843500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33800</td>\n",
       "      <td>0.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34200</td>\n",
       "      <td>0.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34400</td>\n",
       "      <td>0.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34600</td>\n",
       "      <td>0.841400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34800</td>\n",
       "      <td>0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35200</td>\n",
       "      <td>0.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35400</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35600</td>\n",
       "      <td>0.847900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35800</td>\n",
       "      <td>0.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.901600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>0.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36400</td>\n",
       "      <td>0.906100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36600</td>\n",
       "      <td>0.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36800</td>\n",
       "      <td>0.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.870100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37200</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37400</td>\n",
       "      <td>0.896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37600</td>\n",
       "      <td>0.857200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37800</td>\n",
       "      <td>0.862800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.868500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38200</td>\n",
       "      <td>0.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38400</td>\n",
       "      <td>0.902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38600</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38800</td>\n",
       "      <td>0.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39200</td>\n",
       "      <td>0.917600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39400</td>\n",
       "      <td>0.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39600</td>\n",
       "      <td>0.861300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39800</td>\n",
       "      <td>0.941400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.909300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40200</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40400</td>\n",
       "      <td>0.878600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40600</td>\n",
       "      <td>0.898200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40800</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41200</td>\n",
       "      <td>0.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41400</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41600</td>\n",
       "      <td>0.921100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41800</td>\n",
       "      <td>0.919100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42200</td>\n",
       "      <td>0.862900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42400</td>\n",
       "      <td>0.884200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42600</td>\n",
       "      <td>0.898500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42800</td>\n",
       "      <td>0.823300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43200</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43400</td>\n",
       "      <td>0.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43600</td>\n",
       "      <td>0.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43800</td>\n",
       "      <td>0.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.872200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44200</td>\n",
       "      <td>0.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44400</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44600</td>\n",
       "      <td>0.876900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44800</td>\n",
       "      <td>0.904700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45200</td>\n",
       "      <td>0.872900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45400</td>\n",
       "      <td>0.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45600</td>\n",
       "      <td>0.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45800</td>\n",
       "      <td>0.879700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.872900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46200</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46400</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46600</td>\n",
       "      <td>0.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46800</td>\n",
       "      <td>0.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47200</td>\n",
       "      <td>0.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47400</td>\n",
       "      <td>0.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47600</td>\n",
       "      <td>0.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47800</td>\n",
       "      <td>0.870100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48200</td>\n",
       "      <td>0.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48400</td>\n",
       "      <td>0.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48600</td>\n",
       "      <td>0.858700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48800</td>\n",
       "      <td>0.872600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.867200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49200</td>\n",
       "      <td>0.858500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=49224, training_loss=1.0761945511138906, metrics={'train_runtime': 34484.5424, 'train_samples_per_second': 5.709, 'train_steps_per_second': 1.427, 'total_flos': 5.406437630017536e+16, 'train_loss': 1.0761945511138906, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9e9e9-7592-436c-a3a4-b4d9939350e8",
   "metadata": {},
   "source": [
    "### 3.5. Load Models for Evaluation of Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "356b64af-8286-4604-a982-4155689e940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_comparison = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "base_model_comparison = base_model_comparison.to(device)\n",
    "#base_model_comparison.eval()\n",
    "\n",
    "base_model_finetuned = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer_inference = MBart50TokenizerFast.from_pretrained(\"mbart50_lora_final_fixed\")\n",
    "model_inference = PeftModel.from_pretrained(base_model_finetuned, \"mbart50_lora_final_fixed\")\n",
    "model_inference = model_inference.to(device)\n",
    "#model_inference.eval()\n",
    "\n",
    "base_model_fine_tuned2 = merged_model2\n",
    "tokenizer_inference2 = MBart50TokenizerFast.from_pretrained(\"mbart_lora_fixed_round2/checkpoint-49224\")\n",
    "model_inference2 = PeftModel.from_pretrained(base_model_fine_tuned2, \"mbart_lora_fixed_round2/checkpoint-49224\")\n",
    "model_inference2 = model_inference2.to(device)\n",
    "#model_inference2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2391b7-4f9a-453a-9a3c-2525a4df6376",
   "metadata": {},
   "source": [
    "### 3.6. Evaluation of Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230d0d33-2d3a-404d-8e6f-1c95dc3a7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, src=\"en_XX\", tgt=\"es_XX\"):\n",
    "    tokenizer_inference.src_lang = src\n",
    "    \n",
    "    encoded = tokenizer_inference(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    #model_inputs = {k: v.to(model_inference.device) for k, v in encoded.items()}\n",
    "    model_inputs = encoded.to(model_inference.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model_inference.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer_inference.lang_code_to_id[tgt],\n",
    "            max_length=128,\n",
    "            num_beams=5\n",
    "        )\n",
    "    output=tokenizer_inference.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "def translate_base(text, src=\"en_XX\", tgt=\"es_XX\"):\n",
    "    tokenizer.src_lang = src\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    #model_inputs = {k: v.to(base_model_comparison.device) for k, v in encoded.items()}\n",
    "    model_inputs = encoded.to(model_inference.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_tokens = base_model_comparison.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[tgt],\n",
    "            max_length=128,\n",
    "            num_beams=5\n",
    "        )\n",
    "    output=tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "def translate2(text, src=\"en_XX\", tgt=\"es_XX\"):\n",
    "    tokenizer_inference2.src_lang = src\n",
    "    \n",
    "    encoded = tokenizer_inference2(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    #model_inputs = {k: v.to(model_inference.device) for k, v in encoded.items()}\n",
    "    model_inputs = encoded.to(model_inference2.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model_inference2.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer_inference2.lang_code_to_id[tgt],\n",
    "            max_length=128,\n",
    "            num_beams=5\n",
    "        )\n",
    "    output=tokenizer_inference2.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c673344a-9e3c-4443-8d64-f71d93dcc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations2(data, num_samples=500, save_path=\"evaluation_results.csv\"):\n",
    "    results = []\n",
    "    \n",
    "    sample_data = data.select(range(min(num_samples, len(data))))\n",
    "    \n",
    "    for example in tqdm(sample_data):\n",
    "        base_translation = translate_base(\n",
    "            example[\"source\"], \n",
    "            src=example[\"src_lang\"], \n",
    "            tgt=example[\"tgt_lang\"]\n",
    "        )\n",
    "        \n",
    "        fine_tuned_translation = translate(\n",
    "            example[\"source\"], \n",
    "            src=example[\"src_lang\"], \n",
    "            tgt=example[\"tgt_lang\"]\n",
    "        )\n",
    "\n",
    "        fine_tuned_translation2 = translate2(\n",
    "            example[\"source\"], \n",
    "            src=example[\"src_lang\"], \n",
    "            tgt=example[\"tgt_lang\"]\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"input\": example[\"source\"],\n",
    "            \"reference\": example[\"target\"],\n",
    "            \"base_translation\": base_translation,\n",
    "            \"fine_tuned_translation\": fine_tuned_translation,\n",
    "            \"fine_tuned_translation2\": fine_tuned_translation2,\n",
    "            \"task\": f\"{example['src_lang']}->{example['tgt_lang']}\"\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ceb55940-28bb-426c-80bf-5fa049a6cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [08:29<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_df2 = evaluate_translations2(test_data2, num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a751d4-c46f-4af4-b627-c1a4256005ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.1801531344744 23.420922631517467 51.92866366784773 -10.759230502956935 17.748510533373327 28.507741036330263\n"
     ]
    }
   ],
   "source": [
    "bleu_base = sacrebleu.corpus_bleu(\n",
    "    eval_df2[\"base_translation\"].tolist(), \n",
    "    [eval_df2[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "bleu_fine_tuned = sacrebleu.corpus_bleu(\n",
    "    eval_df2[\"fine_tuned_translation\"].tolist(), \n",
    "    [eval_df2[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "bleu_fine_tuned2 = sacrebleu.corpus_bleu(\n",
    "    eval_df2[\"fine_tuned_translation2\"].tolist(), \n",
    "    [eval_df2[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "print(bleu_base.score, bleu_fine_tuned.score, bleu_fine_tuned2.score, bleu_fine_tuned.score - bleu_base.score, bleu_fine_tuned2.score - bleu_base.score, bleu_fine_tuned2.score - bleu_fine_tuned.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52fbc1c4-2a85-4530-b8aa-8772a59bc570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [24:38<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_df3 = evaluate_translations2(test_data, num_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "773b480b-9d5c-462e-99f8-ef4da7ee9515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.798896112501707 19.8223741767145 11.604432934303517 6.023478064212794 -2.1944631781981894 -8.217941242410983\n"
     ]
    }
   ],
   "source": [
    "bleu_base = sacrebleu.corpus_bleu(\n",
    "    eval_df3[\"base_translation\"].tolist(), \n",
    "    [eval_df3[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "bleu_fine_tuned = sacrebleu.corpus_bleu(\n",
    "    eval_df3[\"fine_tuned_translation\"].tolist(), \n",
    "    [eval_df3[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "bleu_fine_tuned2 = sacrebleu.corpus_bleu(\n",
    "    eval_df3[\"fine_tuned_translation2\"].tolist(), \n",
    "    [eval_df3[\"reference\"].tolist()]\n",
    ")\n",
    "\n",
    "print(bleu_base.score, bleu_fine_tuned.score, bleu_fine_tuned2.score, bleu_fine_tuned.score - bleu_base.score, bleu_fine_tuned2.score - bleu_base.score, bleu_fine_tuned2.score - bleu_fine_tuned.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b7faa-9a2b-45eb-a05b-9660e64d57ac",
   "metadata": {},
   "source": [
    "## 4. Implementation and Use Case of Translation Functions\n",
    "As mentioned in the beginning of the Report the use case for this project would have been to create a fine tuned mersion of a model that can be used for transalting text as well as audio input and is trained with a focus on `English`, `German` and `Spanish`. To implement this Use Case another translation function is needed which can be used to translate also audios and can detect the language by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39c0a61f-af0f-44d9-9715-e3f9c594f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > tts_models/de/thorsten/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > tts_models/es/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    }
   ],
   "source": [
    "#used for transcription\n",
    "whisper_model = whisper.load_model(\"small\")  \n",
    "\n",
    "def record_audio(duration=5, filename=\"recording\", samplerate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio = sounddevice.rec(int(duration * samplerate), samplerate=samplerate, channels=1, device=1)\n",
    "    print(\"Time left:\")\n",
    "    for remaining in range(duration, 0, -1):\n",
    "        print(f\"\\r{remaining} ...\", end=\"\", flush=True)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    sounddevice.wait()\n",
    "    now=datetime.now()\n",
    "    filename = filename + now.strftime(\"%m_%d_%Y_%H_%M_%S\")+\".wav\"\n",
    "    write(filename, samplerate, audio)\n",
    "    return filename\n",
    "\n",
    "def transcribe_audio(path, model=whisper_model):\n",
    "    result = model.transcribe(path)\n",
    "    text = result[\"text\"]\n",
    "    return text\n",
    "\n",
    "tts_en = TTS(\"tts_models/en/ljspeech/tacotron2-DDC\")\n",
    "tts_de = TTS(\"tts_models/de/thorsten/vits\")\n",
    "tts_es = TTS(\"tts_models/es/css10/vits\")\n",
    "\n",
    "def play_translation_audio(translation, tgt_in):\n",
    "    match tgt_in:\n",
    "        case \"en\":\n",
    "            tts = tts_en\n",
    "        case \"de\":\n",
    "            tts = tts_de\n",
    "        case \"es\":\n",
    "            tts = tts_es\n",
    "            \n",
    "    audio = tts.tts(translation)\n",
    "\n",
    "    sounddevice.play(audio, samplerate=tts.synthesizer.output_sample_rate, device=2)\n",
    "    sounddevice.wait()\n",
    "\n",
    "def translate_with_lang_detect2(tgt_in, text_in=None, audio_file=None, audio_input=0, audio_output=False):\n",
    "    translations = []\n",
    "    if text_in is not None or audio_file is not None or audio_input > 0:\n",
    "        if audio_input > 0:\n",
    "\n",
    "            audio_file = record_audio(audio_input)\n",
    "        \n",
    "        if audio_file is not None or audio_input > 0:\n",
    "\n",
    "            text_in=transcribe_audio(audio_file)\n",
    "            print(text_in)\n",
    "        \n",
    "        #detect language from written text with detect function from library\n",
    "        src = detect(text_in)\n",
    "    \n",
    "        match src:\n",
    "            case \"en\":\n",
    "                tokenizer_inference.src_lang = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tokenizer_inference.src_lang = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tokenizer_inference.src_lang = \"es_XX\"\n",
    "    \n",
    "        match tgt_in:\n",
    "            case \"en\":\n",
    "                tgt = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tgt = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tgt = \"es_XX\"\n",
    "\n",
    "        text_parts= re.split(r\"(?<=[.!?])\\s+\", text_in)\n",
    "\n",
    "        for text in text_parts:\n",
    "        \n",
    "            encoded = tokenizer_inference2(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            model_inputs = encoded.to(model_inference2.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                generated_tokens = model_inference2.generate(\n",
    "                    **model_inputs,\n",
    "                    forced_bos_token_id=tokenizer_inference2.lang_code_to_id[tgt],\n",
    "                    max_length=128,\n",
    "                    num_beams=5, \n",
    "                    #early_stopping=True,\n",
    "                    #no_repeat_ngram_size=3,  \n",
    "                    #repetition_penalty=1.2\n",
    "                )\n",
    "                \n",
    "            translation=tokenizer_inference2.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "\n",
    "        output = \" \".join(translations)\n",
    "        \n",
    "        \n",
    "        if audio_output is True:\n",
    "            print(\"yes\")\n",
    "            play_translation_audio(output, tgt_in)\n",
    "            \n",
    "        return output\n",
    "    else:\n",
    "        return(\"Invalid input at least one of the three has to be set: text, audio_file or audio_input\")\n",
    "\n",
    "\n",
    "def translate_with_lang_detect(tgt_in, text_in=None, audio_file=None, audio_input=0, audio_output=False):\n",
    "    translations = []\n",
    "    if text_in is not None or audio_file is not None or audio_input > 0:\n",
    "        if audio_input > 0:\n",
    "\n",
    "            audio_file = record_audio(audio_input)\n",
    "        \n",
    "        if audio_file is not None or audio_input > 0:\n",
    "\n",
    "            text_in=transcribe_audio(audio_file)\n",
    "            print(text_in)\n",
    "        \n",
    "        #detect language from written text with detect function from library\n",
    "        src = detect(text_in)\n",
    "    \n",
    "        match src:\n",
    "            case \"en\":\n",
    "                tokenizer_inference.src_lang = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tokenizer_inference.src_lang = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tokenizer_inference.src_lang = \"es_XX\"\n",
    "    \n",
    "        match tgt_in:\n",
    "            case \"en\":\n",
    "                tgt = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tgt = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tgt = \"es_XX\"\n",
    "\n",
    "        text_parts= re.split(r\"(?<=[.!?])\\s+\", text_in)\n",
    "\n",
    "        for text in text_parts:\n",
    "        \n",
    "            encoded = tokenizer_inference(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            model_inputs = encoded.to(model_inference.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                generated_tokens = model_inference.generate(\n",
    "                    **model_inputs,\n",
    "                    forced_bos_token_id=tokenizer_inference.lang_code_to_id[tgt],\n",
    "                    max_length=128,\n",
    "                    num_beams=5, \n",
    "                    #early_stopping=True,\n",
    "                    #no_repeat_ngram_size=3,  \n",
    "                    #repetition_penalty=1.2\n",
    "                )\n",
    "                \n",
    "            translation=tokenizer_inference.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "\n",
    "        output = \" \".join(translations)\n",
    "        \n",
    "        \n",
    "        if audio_output is True:\n",
    "            print(\"yes\")\n",
    "            play_translation_audio(output, tgt_in)\n",
    "            \n",
    "        return output\n",
    "    else:\n",
    "        return(\"Invalid input at least one of the three has to be set: text, audio_file or audio_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c63eb9e3-2f03-49bd-a2fe-7385145262dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_lang_detect3(tgt_in, text_in=None, audio_file=None, audio_input=0, audio_output=False):\n",
    "    translations = []\n",
    "    if text_in is not None or audio_file is not None or audio_input > 0:\n",
    "        if audio_input > 0:\n",
    "\n",
    "            audio_file = record_audio(audio_input)\n",
    "        \n",
    "        if audio_file is not None or audio_input > 0:\n",
    "\n",
    "            text_in=transcribe_audio(audio_file)\n",
    "            print(text_in)\n",
    "        \n",
    "        #detect language from written text with detect function from library\n",
    "        src = detect(text_in)\n",
    "    \n",
    "        match src:\n",
    "            case \"en\":\n",
    "                tokenizer.src_lang = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tokenizer.src_lang = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tokenizer.src_lang = \"es_XX\"\n",
    "    \n",
    "        match tgt_in:\n",
    "            case \"en\":\n",
    "                tgt = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tgt = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tgt = \"es_XX\"\n",
    "\n",
    "        text_parts= re.split(r\"(?<=[.!?])\\s+\", text_in)\n",
    "\n",
    "        for text in text_parts:\n",
    "        \n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            model_inputs = encoded.to(model_inference2.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                generated_tokens = model_inference2.generate(\n",
    "                    **model_inputs,\n",
    "                    forced_bos_token_id=tokenizer.lang_code_to_id[tgt],\n",
    "                    max_length=128,\n",
    "                    num_beams=5, \n",
    "                    #early_stopping=True,\n",
    "                    #no_repeat_ngram_size=3,  \n",
    "                    #repetition_penalty=1.2\n",
    "                )\n",
    "                \n",
    "            translation=tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "\n",
    "        output = \" \".join(translations)\n",
    "        \n",
    "        \n",
    "        if audio_output is True:\n",
    "            print(\"yes\")\n",
    "            play_translation_audio(output, tgt_in)\n",
    "            \n",
    "        return output\n",
    "    else:\n",
    "        return(\"Invalid input at least one of the three has to be set: text, audio_file or audio_input\")\n",
    "\n",
    "\n",
    "def translate_with_lang_detect4(tgt_in, text_in=None, audio_file=None, audio_input=0, audio_output=False):\n",
    "    translations = []\n",
    "    if text_in is not None or audio_file is not None or audio_input > 0:\n",
    "        if audio_input > 0:\n",
    "\n",
    "            audio_file = record_audio(audio_input)\n",
    "        \n",
    "        if audio_file is not None or audio_input > 0:\n",
    "\n",
    "            text_in=transcribe_audio(audio_file)\n",
    "            print(text_in)\n",
    "        \n",
    "        #detect language from written text with detect function from library\n",
    "        src = detect(text_in)\n",
    "    \n",
    "        match src:\n",
    "            case \"en\":\n",
    "                tokenizer.src_lang = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tokenizer.src_lang = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tokenizer.src_lang = \"es_XX\"\n",
    "    \n",
    "        match tgt_in:\n",
    "            case \"en\":\n",
    "                tgt = \"en_XX\"\n",
    "            case \"de\":\n",
    "                tgt = \"de_DE\"\n",
    "            case \"es\": \n",
    "                tgt = \"es_XX\"\n",
    "\n",
    "        text_parts= re.split(r\"(?<=[.!?])\\s+\", text_in)\n",
    "\n",
    "        for text in text_parts:\n",
    "        \n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            model_inputs = encoded.to(model_inference.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                generated_tokens = model_inference.generate(\n",
    "                    **model_inputs,\n",
    "                    forced_bos_token_id=tokenizer.lang_code_to_id[tgt],\n",
    "                    max_length=128,\n",
    "                    num_beams=5, \n",
    "                    #early_stopping=True,\n",
    "                    #no_repeat_ngram_size=3,  \n",
    "                    #repetition_penalty=1.2\n",
    "                )\n",
    "                \n",
    "            translation=tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "\n",
    "        output = \" \".join(translations)\n",
    "        \n",
    "        \n",
    "        if audio_output is True:\n",
    "            print(\"yes\")\n",
    "            play_translation_audio(output, tgt_in)\n",
    "            \n",
    "        return output\n",
    "    else:\n",
    "        return(\"Invalid input at least one of the three has to be set: text, audio_file or audio_input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d1e8c-d5b1-4072-9a5e-076594b55972",
   "metadata": {},
   "source": [
    "### Testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63af9c98-4ddb-4ca6-868f-e7271557c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hallo mein name ist Simon und ich bin ein astronaut und ich liebe es in den schwitzischen berg zu skien und danach eine gute heiße chocolate zu trinken'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect2(text_in=\"Hello, my name is Simon and i am an astronaut and i really love skiing in the mountains of switzerland and to drink afterwards a good hot chocolate.\", tgt_in=\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b8ae44e-16cf-4103-8078-19b1d291473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hallo mein name ist Simon und ich bin ein astronaut und ich liebe es in den schwitzischen Bergen zu skien und danach eine gute heiße chokolade zu trinken'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect3(text_in=\"Hello, my name is Simon and i am an astronaut and i really love skiing in the mountains of switzerland and to drink afterwards a good hot chocolate.\", tgt_in=\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba303516-2d11-4c08-a188-313d3685b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Invalid input at least one of the three has to be set: text, audio_file or audio_input'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect2(tgt_in=\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "caba0574-e9fb-4e25-bddd-25f164da0e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello hello how are you doing? I'm fine thank you how are you?\n",
      "yes\n",
      " > Text splitted to sentences.\n",
      "['hallo hallo wie gehts dir ich bin in Ordnung danke wie gehts dir']\n",
      " > Processing time: 0.9087660312652588\n",
      " > Real-time factor: 0.20433891121511416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hallo hallo wie gehts dir ich bin in Ordnung danke wie gehts dir'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect2(audio_file=\"recording11_23_2025_01_02_17.wav\",tgt_in=\"de\", audio_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d222c4a1-9083-4625-9dfa-fc89eceda835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      " > Text splitted to sentences.\n",
      "['hola hola como estás estoy bien gracias como estas']\n",
      " > Processing time: 0.1888437271118164\n",
      " > Real-time factor: 0.050348280407423486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hola hola como estás estoy bien gracias como estas'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect2(text_in=\"Hello hello how are you doing? I'm fine thank you how are you?\",tgt_in=\"es\", audio_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8a4582bb-468e-46d7-abf9-3568c3e47582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      " > Text splitted to sentences.\n",
      "['hola como te va estoy bien gracias como estas']\n",
      " > Processing time: 0.1624300479888916\n",
      " > Real-time factor: 0.0460121089177166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hola como te va estoy bien gracias como estas'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect3(text_in=\"Hello hello how are you doing? I'm fine thank you how are you?\",tgt_in=\"es\", audio_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a76e7fcb-cdf1-4109-9b35-28848b1bd445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      " > Text splitted to sentences.\n",
      "['Hallo, hello, wie bist du dabei?', \"I'm fine thank you how are you?\"]\n",
      " > Processing time: 1.6352949142456055\n",
      " > Real-time factor: 0.2677168928123931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hallo, hello, wie bist du dabei? I'm fine thank you how are you?\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect(text_in=\"Hello hello how are you doing? I'm fine thank you how are you?\",tgt_in=\"de\", audio_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eddac72e-1b4b-4239-974d-841b0afe1f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo, Hallo, wie geht es dir? Ich bin in Ordnung. Danke, wie geht es dir?'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect4(text_in=\"Hello hello how are you doing? I'm fine thank you how are you?\",tgt_in=\"de\", audio_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8a63c3dc-6ac9-4eac-8c8b-cb8c0e987aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how are you? I am all right. Thank you, how are you?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect4(text_in='Hallo, Hallo, wie geht es dir? Ich bin in Ordnung. Danke, wie geht es dir?'\n",
    ",tgt_in=\"en\", audio_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4cae8965-c889-4f53-8c06-4ae0380583a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, hello how are you i am fine thank you how are you'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect3(text_in='Hallo, Hallo, wie geht es dir? Ich bin in Ordnung. Danke, wie geht es dir?'\n",
    ",tgt_in=\"en\", audio_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7b87743-d0fa-42ef-9ce3-7e8015c36c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hallo hallo wie gehts dir ich bin gut danke wie gehts dir'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect3(text_in='hello, hello how are you i am fine thank you how are you',tgt_in=\"de\", audio_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2773be2f-7a33-4a54-8511-14fb0c60c426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, hello how are you i am fine thank you how are you'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_lang_detect3(text_in='Hallo, Hallo, wie geht es dir? Mir geht es gut. Danke, wie geht es dir?'\n",
    ",tgt_in=\"en\", audio_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cc611c2-8223-43f4-a6ea-ee8a93f6e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sounddevice.query_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266ca8b-5e7f-442e-a9c3-2a8e5a2007e8",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "As can be seen both iterations show very different outputs while the first iteration was good at translating longer passages the second iteration needed some help by splitting longer text into short since it was not trained on text containing punctuation for a third iteration it would be great to use a dataset containing correct syntax as well as modern text. Due to the time constraint of each fine tuning iteration taking around 10 to 15 hours and issues in the first few iterations there was simply no time for a third iteration. The second iteration is definitely an improvement in modern speech but sadly has no punctuation and does not recognize which words should be capitalized and which not. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (translation_env)",
   "language": "python",
   "name": "translation_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
